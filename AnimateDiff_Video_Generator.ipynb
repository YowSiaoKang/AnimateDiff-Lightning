{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f7616-fdf0-4d40-96ad-ca7c2f15afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from diffusers import AnimateDiffPipeline, MotionAdapter, DDIMScheduler, EulerDiscreteScheduler\n",
    "from diffusers.utils import export_to_gif\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Common parameters\n",
    "device = \"cuda\"\n",
    "dtype = torch.float16\n",
    "base = \"emilianJR/epiCRealism\"  # Choose your favorite base model.\n",
    "prompt = \"A brave knight rescuing a princess from a dragon's lair.\"\n",
    "negative_prompt = \"bad quality, worse quality\"\n",
    "num_frames = 24\n",
    "guidance_scale = 5.0  # Adjusted guidance scale for better quality\n",
    "num_inference_steps = 100  # Increased number of inference steps for better quality\n",
    "seed = 42  # Use the same seed for reproducibility\n",
    "\n",
    "# Function to initialize pipeline\n",
    "def initialize_pipeline(repo, ckpt, base, device, dtype, use_checkpoint=True, scheduler_type=\"DDIM\"):\n",
    "    adapter = MotionAdapter().to(device, dtype)\n",
    "    if use_checkpoint:\n",
    "        adapter.load_state_dict(load_file(hf_hub_download(repo, ckpt), device=device))\n",
    "    else:\n",
    "        adapter = MotionAdapter.from_pretrained(repo, torch_dtype=dtype).to(device)\n",
    "    pipe = AnimateDiffPipeline.from_pretrained(base, motion_adapter=adapter, torch_dtype=dtype).to(device)\n",
    "    if scheduler_type == \"DDIM\":\n",
    "        pipe.scheduler = DDIMScheduler.from_pretrained(\n",
    "            base,\n",
    "            subfolder=\"scheduler\",\n",
    "            clip_sample=False,\n",
    "            timestep_spacing=\"trailing\",\n",
    "            beta_schedule=\"linear\",\n",
    "            steps_offset=1,\n",
    "        )\n",
    "    elif scheduler_type == \"Euler\":\n",
    "        pipe.scheduler = EulerDiscreteScheduler.from_config(\n",
    "            pipe.scheduler.config,\n",
    "            clip_sample=False,\n",
    "            timestep_spacing=\"trailing\",\n",
    "            beta_schedule=\"linear\",\n",
    "            steps_offset=1,\n",
    "        )\n",
    "    pipe.enable_vae_slicing()\n",
    "    pipe.enable_model_cpu_offload()\n",
    "    return pipe\n",
    "\n",
    "# Initialize Lightning pipeline with EulerDiscreteScheduler\n",
    "step = 8  # Options: [1,2,4,8]\n",
    "repo_lightning = \"ByteDance/AnimateDiff-Lightning\"\n",
    "ckpt_lightning = f\"animatediff_lightning_{step}step_diffusers.safetensors\"\n",
    "lightning_pipe = initialize_pipeline(repo_lightning, ckpt_lightning, base, device, dtype, use_checkpoint=True, scheduler_type=\"Euler\")\n",
    "\n",
    "# Initialize Original pipeline with DDIMScheduler\n",
    "repo_original = \"guoyww/animatediff-motion-adapter-v1-5-2\"\n",
    "original_pipe = initialize_pipeline(repo_original, None, base, device, dtype, use_checkpoint=False, scheduler_type=\"DDIM\")\n",
    "\n",
    "# Function to generate GIF\n",
    "def generate_gif(pipe, prompt, negative_prompt, num_frames, guidance_scale, num_inference_steps, seed, filename):\n",
    "    output = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_frames=num_frames,\n",
    "        guidance_scale=guidance_scale,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        generator=torch.Generator(device).manual_seed(seed)\n",
    "    )\n",
    "    export_to_gif(output.frames[0], filename)\n",
    "    print(f\"{filename} created\")\n",
    "    display(Image(filename))\n",
    "\n",
    "# Generate GIFs\n",
    "generate_gif(lightning_pipe, prompt, negative_prompt, num_frames, guidance_scale, num_inference_steps, seed, \"lightning_animation.gif\")\n",
    "generate_gif(original_pipe, prompt, negative_prompt, num_frames, guidance_scale, num_inference_steps, seed, \"original_animation.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b92cd0a-76f6-4321-89e5-d8007aaecf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A cozy cabin with snow falling outside.\"\n",
    "\n",
    "generate_gif(lightning_pipe, prompt, negative_prompt, num_frames, guidance_scale, num_inference_steps, seed, \"lightning_animation.gif\")\n",
    "generate_gif(original_pipe, prompt, negative_prompt, num_frames, guidance_scale, num_inference_steps, seed, \"original_animation.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeec8b6-ffa7-47e5-9588-0ab571abd17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "prompts_file = \"Text_Prompts.json\"\n",
    "output_dir = \"Generated_GIFs\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load prompts from JSON file\n",
    "with open(prompts_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for theme in data[\"Themes\"]:\n",
    "    theme_name = theme[\"Name\"].replace(\" \", \"_\")\n",
    "    theme_dir = os.path.join(output_dir, theme_name)\n",
    "    os.makedirs(theme_dir, exist_ok=True)\n",
    "    \n",
    "    for idx, prompt in enumerate(theme[\"Prompts\"], 1):\n",
    "        for model_name, pipe in [(\"lightning_pipe\", lightning_pipe), (\"original_pipe\", original_pipe)]:\n",
    "            model_dir = os.path.join(theme_dir, model_name)\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            \n",
    "            filename = f\"{theme_name}_{model_name}_Prompt{idx}.gif\"\n",
    "            filepath = os.path.join(model_dir, filename)\n",
    "            \n",
    "            generate_gif(\n",
    "                pipe=pipe,\n",
    "                prompt=prompt,\n",
    "                negative_prompt=\"bad quality, worse quality\",  # Update if needed\n",
    "                num_frames=num_frames,\n",
    "                guidance_scale=guidance_scale,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                seed=seed,\n",
    "                filename=filepath,\n",
    "            )\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7496ea6-794c-4d97-9d6a-39bfdaa76f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
